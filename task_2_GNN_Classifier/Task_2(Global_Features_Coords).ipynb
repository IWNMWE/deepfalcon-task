{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEQVCuWeiC7d",
        "outputId": "3aecc80f-d9dd-497d-8310-f389d9f9d8b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.13)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.1.31)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MT3PS2g7Sehu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch_geometric\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch_geometric.data import Data, Batch\n",
        "from torch_geometric.loader import DataLoader\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "from torch.nn import Linear"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "dKBlhLaOX0Ic"
      },
      "outputs": [],
      "source": [
        "Data_Path = '/content/drive/MyDrive/quark-gluon_data-set_n139306.hdf5'\n",
        "Data_Size = 10000\n",
        "k = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dArvmmKg11Ln"
      },
      "outputs": [],
      "source": [
        "# The coords of the data in the 125 x 125 grid is appended to the data\n",
        "# This is done to be able to use the data later for GAE model\n",
        "data = h5py.File(Data_Path, \"r\")\n",
        "images = data['X_jets'][0:Data_Size]\n",
        "labels = data['y'][0:Data_Size]\n",
        "coords = np.indices((125, 125))\n",
        "coords = np.moveaxis(coords, 1, -1).T\n",
        "coords = np.expand_dims(coords, axis=0)\n",
        "# coords are normalized to be in the range [0, 1]\n",
        "coords = coords.astype(np.float32) / 125.\n",
        "coords = np.repeat(coords, 10000, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fo3IiC3VObIX"
      },
      "outputs": [],
      "source": [
        "# Some initial fetures were provided in the dataset m0 and pt which are used as global features\n",
        "# The global features are log transformed\n",
        "global_feats = np.vstack((data['m0'][:Data_Size], data['pt'][:Data_Size])).T\n",
        "global_feats =torch.log1p(torch.from_numpy(global_feats))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "3AS17U6-5ZwQ"
      },
      "outputs": [],
      "source": [
        "images_with_coords = np.concatenate((images, coords), axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "1g4FSNy4-lHH"
      },
      "outputs": [],
      "source": [
        "del coords\n",
        "del images\n",
        "del data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woZEqeLlXZLy",
        "outputId": "94aa48f6-228e-46d7-f80c-448ecd1473a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(884, 5)\n"
          ]
        }
      ],
      "source": [
        "# Reshape the data to be compatible with torch_geometric\n",
        "data = images_with_coords.reshape((-1, images_with_coords.shape[1]*images_with_coords.shape[2], 5))\n",
        "non_black_pixels_mask = np.any(data[..., :3] != [0., 0., 0.], axis=-1)\n",
        "del images_with_coords\n",
        "node_list = []\n",
        "for i, x in enumerate(data):\n",
        "    node_list.append(x[non_black_pixels_mask[i]])\n",
        "\n",
        "\n",
        "dataset = []\n",
        "for i, nodes in enumerate(node_list):\n",
        "    if i == 0:\n",
        "      print(nodes.shape)\n",
        "    edges = kneighbors_graph(nodes[...,3:], k, mode='connectivity', include_self=True)\n",
        "    c = edges.tocoo()\n",
        "    edge_list = torch.from_numpy(np.vstack((c.row, c.col))).type(torch.long)\n",
        "    edge_weight = torch.from_numpy(c.data.reshape(-1, 1))\n",
        "    y = torch.tensor([int(labels[i])], dtype=torch.long)\n",
        "    data = Data(x=torch.from_numpy(nodes), edge_index=edge_list, edge_attr=edge_weight, y=y, global_feat=global_feats[i,None])\n",
        "    dataset.append(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJTrXwEWDbQn"
      },
      "outputs": [],
      "source": [
        "# The classifictaion model was traned on a subset of the full dataset\n",
        "train_loader = DataLoader(dataset[:8000], batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(dataset[8000:9000], batch_size=32, shuffle=False)\n",
        "val_loader = DataLoader(dataset[9000:], batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a19T83xxIdSa"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "class GCNClassifier(torch.nn.Module):\n",
        "  def __init__(self, input_embed_dim : int, latent_dim = None,  num_classes : int = 2):\n",
        "    super(GCNClassifier, self).__init__()\n",
        "    self.node_dim = input_embed_dim\n",
        "    if latent_dim is None:\n",
        "      self.latent_dim = self.node_dim\n",
        "    else:\n",
        "      self.latent_dim = latent_dim\n",
        "    self.num_classes = num_classes\n",
        "    self.Conv1 = GCNConv(self.node_dim, self.latent_dim)\n",
        "    self.Conv2 = GCNConv(self.latent_dim, 2*self.latent_dim)\n",
        "    self.Conv3 = GCNConv(2*self.latent_dim, 4*self.latent_dim)\n",
        "    self.lin1 = torch.nn.Linear(4*self.latent_dim + 2, 2*self.latent_dim)\n",
        "    self.lin2 = torch.nn.Linear(2*self.latent_dim, self.latent_dim)\n",
        "    self.lin3 = torch.nn.Linear(self.latent_dim, 4*self.num_classes)\n",
        "    self.lin4 = torch.nn.Linear(4*self.num_classes, self.num_classes)\n",
        "    self.m = nn.Dropout(p=0.5)\n",
        "\n",
        "  def forward(self, x, edge_index, batch, global_feat):\n",
        "    x = F.relu(self.Conv1(x, edge_index))\n",
        "    x = F.relu(self.Conv2(x, edge_index))\n",
        "    x = F.relu(self.Conv3(x, edge_index))\n",
        "\n",
        "    x = global_mean_pool(x, batch)\n",
        "    # Global features are appended to the latent variables\n",
        "    x = torch.cat((x, global_feat), dim=1)\n",
        "    x = F.relu(self.lin1(x))\n",
        "    x = self.m(x)\n",
        "    x = F.relu(self.lin2(x))\n",
        "    x = self.m(x)\n",
        "    x = F.relu(self.lin3(x))\n",
        "    x = F.sigmoid(self.lin4(x))\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QaiW8EpAXiyy"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn import SAGEConv\n",
        "\n",
        "class SAGEClassifier(torch.nn.Module):\n",
        "  def __init__(self, input_embed_dim : int, latent_dim = None,  num_classes : int = 2):\n",
        "    super(SAGEClassifier, self).__init__()\n",
        "    self.node_dim = input_embed_dim\n",
        "    if latent_dim is None:\n",
        "      self.latent_dim = self.node_dim\n",
        "    else:\n",
        "      self.latent_dim = latent_dim\n",
        "    self.num_classes = num_classes\n",
        "    self.Conv1 = SAGEConv(self.node_dim, self.latent_dim, project = True)\n",
        "    self.Conv2 = SAGEConv(self.latent_dim, 2*self.latent_dim, project = True)\n",
        "    self.Conv3 = SAGEConv(2*self.latent_dim, 4*self.latent_dim, project = True)\n",
        "    self.lin1 = torch.nn.Linear(4*self.latent_dim + 2, 2*self.latent_dim)\n",
        "    self.lin2 = torch.nn.Linear(2*self.latent_dim, self.latent_dim)\n",
        "    self.lin3 = torch.nn.Linear(self.latent_dim, 4*self.num_classes)\n",
        "    self.lin4 = torch.nn.Linear(4*self.num_classes, self.num_classes)\n",
        "    self.m = nn.Dropout(p=0.5)\n",
        "\n",
        "  def forward(self, x, edge_index, batch, global_feat):\n",
        "    x = self.Conv1(x, edge_index)\n",
        "    x = self.Conv2(x, edge_index)\n",
        "    x = self.Conv3(x, edge_index)\n",
        "\n",
        "    x = global_mean_pool(x, batch)\n",
        "    # Global features are appended to the latent variables\n",
        "    x = torch.cat((x, global_feat), dim=1)\n",
        "    x = F.relu(self.lin1(x))\n",
        "    x = self.m(x)\n",
        "    x = F.relu(self.lin2(x))\n",
        "    x = self.m(x)\n",
        "    x = F.relu(self.lin3(x))\n",
        "    x = F.sigmoid(self.lin4(x))\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6gCqrEqXoTd"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn import GATConv\n",
        "\n",
        "class GATClassifier(torch.nn.Module):\n",
        "  def __init__(self, input_embed_dim : int, latent_dim = None,  num_classes : int = 2, attn_heads = None):\n",
        "    super(GATClassifier, self).__init__()\n",
        "    self.node_dim = input_embed_dim\n",
        "    if latent_dim is None:\n",
        "      self.latent_dim = self.node_dim\n",
        "    else:\n",
        "      self.latent_dim = latent_dim\n",
        "    if attn_heads is None:\n",
        "      self.attn_heads = 3\n",
        "    else:\n",
        "      self.attn_heads = attn_heads\n",
        "    self.num_classes = num_classes\n",
        "    self.Conv1 = GATConv(self.node_dim, self.latent_dim)\n",
        "    self.Conv2 = GATConv(self.latent_dim, 2*self.latent_dim)\n",
        "    self.Conv3 = GATConv(2*self.latent_dim, 4*self.latent_dim)\n",
        "    self.lin1 = torch.nn.Linear(4*self.latent_dim + 2, 2*self.latent_dim)\n",
        "    self.lin2 = torch.nn.Linear(2*self.latent_dim, self.latent_dim)\n",
        "    self.lin3 = torch.nn.Linear(self.latent_dim, 4*self.num_classes)\n",
        "    self.lin4 = torch.nn.Linear(4*self.num_classes, self.num_classes)\n",
        "    self.m = nn.Dropout(p=0.5)\n",
        "\n",
        "  def forward(self, x, edge_index, batch, global_feat):\n",
        "    x = F.relu(self.Conv1(x, edge_index))\n",
        "    x = F.relu(self.Conv2(x, edge_index))\n",
        "    x = F.relu(self.Conv3(x, edge_index))\n",
        "\n",
        "    x = global_mean_pool(x, batch)\n",
        "    # Global features are appended to the latent variables\n",
        "    x = torch.cat((x, global_feat), dim=1)\n",
        "    x = F.relu(self.lin1(x))\n",
        "    x = self.m(x)\n",
        "    x = F.relu(self.lin2(x))\n",
        "    x = self.m(x)\n",
        "    x = F.relu(self.lin3(x))\n",
        "    x = F.sigmoid(self.lin4(x))\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "eDPGYgG1ewJ1"
      },
      "outputs": [],
      "source": [
        "def train():\n",
        "    model.train()\n",
        "\n",
        "    for data in train_loader:\n",
        "         data = data.to(torch.device('cuda'))\n",
        "         out = model(data.x, data.edge_index, data.batch, data.global_feat)\n",
        "         loss = criterion(out, data.y)\n",
        "         loss.backward()\n",
        "         optimizer.step()\n",
        "         optimizer.zero_grad()\n",
        "\n",
        "def test(loader):\n",
        "     model.eval()\n",
        "\n",
        "     correct = 0\n",
        "     for data in loader:\n",
        "         data = data.to(torch.device('cuda'))\n",
        "         out = model(data.x, data.edge_index, data.batch, data.global_feat)\n",
        "         pred = out.argmax(dim=1)\n",
        "         correct += int((pred == data.y).sum())\n",
        "     return correct / len(loader.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4LolnX4f6uw",
        "outputId": "e9168f47-daa2-4736-eb1c-a2ebfee3a43a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 000, Train Acc: 0.4993, Test Acc: 0.5040, Val Acc: 0.4960\n",
            "Epoch: 001, Train Acc: 0.4993, Test Acc: 0.5040, Val Acc: 0.4960\n",
            "Epoch: 002, Train Acc: 0.4993, Test Acc: 0.5040, Val Acc: 0.4960\n",
            "Epoch: 003, Train Acc: 0.5109, Test Acc: 0.5140, Val Acc: 0.5110\n",
            "Epoch: 004, Train Acc: 0.5006, Test Acc: 0.4960, Val Acc: 0.5040\n",
            "Epoch: 005, Train Acc: 0.6746, Test Acc: 0.6880, Val Acc: 0.6910\n",
            "Epoch: 006, Train Acc: 0.6953, Test Acc: 0.7330, Val Acc: 0.7000\n",
            "Epoch: 007, Train Acc: 0.6993, Test Acc: 0.7390, Val Acc: 0.6990\n",
            "Epoch: 008, Train Acc: 0.6949, Test Acc: 0.7330, Val Acc: 0.6970\n",
            "Epoch: 009, Train Acc: 0.6999, Test Acc: 0.7340, Val Acc: 0.7040\n",
            "Epoch: 010, Train Acc: 0.6975, Test Acc: 0.7320, Val Acc: 0.7010\n",
            "Epoch: 011, Train Acc: 0.7000, Test Acc: 0.7420, Val Acc: 0.6920\n",
            "Epoch: 012, Train Acc: 0.6977, Test Acc: 0.7390, Val Acc: 0.6950\n",
            "Epoch: 013, Train Acc: 0.7009, Test Acc: 0.7420, Val Acc: 0.6990\n",
            "Epoch: 014, Train Acc: 0.7016, Test Acc: 0.7430, Val Acc: 0.7030\n",
            "Epoch: 015, Train Acc: 0.7007, Test Acc: 0.7460, Val Acc: 0.6960\n",
            "Epoch: 016, Train Acc: 0.6975, Test Acc: 0.7180, Val Acc: 0.7010\n",
            "Epoch: 017, Train Acc: 0.7035, Test Acc: 0.7460, Val Acc: 0.7000\n",
            "Epoch: 018, Train Acc: 0.7033, Test Acc: 0.7350, Val Acc: 0.7050\n",
            "Epoch: 019, Train Acc: 0.7034, Test Acc: 0.7300, Val Acc: 0.7030\n",
            "Epoch: 020, Train Acc: 0.7040, Test Acc: 0.7370, Val Acc: 0.7090\n",
            "Epoch: 021, Train Acc: 0.7023, Test Acc: 0.7290, Val Acc: 0.7050\n",
            "Epoch: 022, Train Acc: 0.7021, Test Acc: 0.7370, Val Acc: 0.7020\n",
            "Epoch: 023, Train Acc: 0.7029, Test Acc: 0.7320, Val Acc: 0.6940\n",
            "Epoch: 024, Train Acc: 0.6970, Test Acc: 0.7080, Val Acc: 0.7090\n",
            "Epoch: 025, Train Acc: 0.7030, Test Acc: 0.7430, Val Acc: 0.6990\n",
            "Epoch: 026, Train Acc: 0.7037, Test Acc: 0.7400, Val Acc: 0.7050\n",
            "Epoch: 027, Train Acc: 0.7019, Test Acc: 0.7300, Val Acc: 0.7100\n",
            "Epoch: 028, Train Acc: 0.6944, Test Acc: 0.6990, Val Acc: 0.7030\n",
            "Epoch: 029, Train Acc: 0.6993, Test Acc: 0.7350, Val Acc: 0.6900\n",
            "Epoch: 030, Train Acc: 0.7036, Test Acc: 0.7450, Val Acc: 0.6990\n",
            "Epoch: 031, Train Acc: 0.7040, Test Acc: 0.7380, Val Acc: 0.7080\n",
            "Epoch: 032, Train Acc: 0.7037, Test Acc: 0.7370, Val Acc: 0.7080\n",
            "Epoch: 033, Train Acc: 0.7055, Test Acc: 0.7390, Val Acc: 0.7050\n",
            "Epoch: 034, Train Acc: 0.7049, Test Acc: 0.7330, Val Acc: 0.7060\n",
            "Epoch: 035, Train Acc: 0.7060, Test Acc: 0.7320, Val Acc: 0.7130\n",
            "Epoch: 036, Train Acc: 0.7033, Test Acc: 0.7120, Val Acc: 0.7150\n",
            "Epoch: 037, Train Acc: 0.7024, Test Acc: 0.7190, Val Acc: 0.7090\n",
            "Epoch: 038, Train Acc: 0.6996, Test Acc: 0.7140, Val Acc: 0.7110\n",
            "Epoch: 039, Train Acc: 0.7030, Test Acc: 0.7340, Val Acc: 0.6940\n",
            "Epoch: 040, Train Acc: 0.7085, Test Acc: 0.7340, Val Acc: 0.7050\n",
            "Epoch: 041, Train Acc: 0.7046, Test Acc: 0.7320, Val Acc: 0.7010\n",
            "Epoch: 042, Train Acc: 0.7046, Test Acc: 0.7310, Val Acc: 0.7130\n",
            "Epoch: 043, Train Acc: 0.7026, Test Acc: 0.7110, Val Acc: 0.7080\n",
            "Epoch: 044, Train Acc: 0.7049, Test Acc: 0.7250, Val Acc: 0.7130\n",
            "Epoch: 045, Train Acc: 0.7084, Test Acc: 0.7400, Val Acc: 0.7080\n",
            "Epoch: 046, Train Acc: 0.7001, Test Acc: 0.7300, Val Acc: 0.6970\n",
            "Epoch: 047, Train Acc: 0.7051, Test Acc: 0.7330, Val Acc: 0.6960\n",
            "Epoch: 048, Train Acc: 0.7016, Test Acc: 0.7090, Val Acc: 0.7100\n",
            "Epoch: 049, Train Acc: 0.7031, Test Acc: 0.7340, Val Acc: 0.6960\n",
            "Epoch: 050, Train Acc: 0.7050, Test Acc: 0.7290, Val Acc: 0.7050\n",
            "Epoch: 051, Train Acc: 0.7011, Test Acc: 0.7350, Val Acc: 0.6960\n",
            "Epoch: 052, Train Acc: 0.7061, Test Acc: 0.7430, Val Acc: 0.7120\n",
            "Epoch: 053, Train Acc: 0.7020, Test Acc: 0.7320, Val Acc: 0.6920\n",
            "Epoch: 054, Train Acc: 0.7056, Test Acc: 0.7370, Val Acc: 0.7030\n",
            "Epoch: 055, Train Acc: 0.7054, Test Acc: 0.7250, Val Acc: 0.7050\n",
            "Epoch: 056, Train Acc: 0.7101, Test Acc: 0.7290, Val Acc: 0.7110\n",
            "Epoch: 057, Train Acc: 0.7086, Test Acc: 0.7400, Val Acc: 0.6970\n",
            "Epoch: 058, Train Acc: 0.7074, Test Acc: 0.7430, Val Acc: 0.7080\n",
            "Epoch: 059, Train Acc: 0.7081, Test Acc: 0.7310, Val Acc: 0.6960\n"
          ]
        }
      ],
      "source": [
        "model = SAGEClassifier(5,32).to(torch.device('cuda'))\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(60):\n",
        "    train()\n",
        "    train_acc = test(train_loader)\n",
        "    test_acc = test(test_loader)\n",
        "    val_acc = test(val_loader)\n",
        "    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}, Val Acc: {val_acc:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03rjp0Xxm9lS",
        "outputId": "42d9ba67-cd75-4278-91ad-80f60a8ba46e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.696"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test(val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "OuvQkzN094j4"
      },
      "outputs": [],
      "source": [
        "torch.save(model, \"sage_gnn_gfc.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPsZQQJ7eplZ",
        "outputId": "ce2c626a-5c00-40ec-c4c5-011c3d285add"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 000, Train Acc: 0.5008, Test Acc: 0.4960, Val Acc: 0.5040\n",
            "Epoch: 001, Train Acc: 0.4993, Test Acc: 0.5040, Val Acc: 0.4960\n",
            "Epoch: 002, Train Acc: 0.6079, Test Acc: 0.6240, Val Acc: 0.6100\n",
            "Epoch: 003, Train Acc: 0.5316, Test Acc: 0.5400, Val Acc: 0.5280\n",
            "Epoch: 004, Train Acc: 0.6358, Test Acc: 0.6280, Val Acc: 0.6350\n",
            "Epoch: 005, Train Acc: 0.6624, Test Acc: 0.6570, Val Acc: 0.6500\n",
            "Epoch: 006, Train Acc: 0.6496, Test Acc: 0.6440, Val Acc: 0.6400\n",
            "Epoch: 007, Train Acc: 0.6620, Test Acc: 0.6750, Val Acc: 0.6520\n",
            "Epoch: 008, Train Acc: 0.6661, Test Acc: 0.6650, Val Acc: 0.6500\n",
            "Epoch: 009, Train Acc: 0.6673, Test Acc: 0.6620, Val Acc: 0.6590\n",
            "Epoch: 010, Train Acc: 0.6931, Test Acc: 0.7020, Val Acc: 0.6860\n",
            "Epoch: 011, Train Acc: 0.7013, Test Acc: 0.7070, Val Acc: 0.6870\n",
            "Epoch: 012, Train Acc: 0.7076, Test Acc: 0.7220, Val Acc: 0.7000\n",
            "Epoch: 013, Train Acc: 0.7053, Test Acc: 0.7280, Val Acc: 0.6950\n",
            "Epoch: 014, Train Acc: 0.7045, Test Acc: 0.7180, Val Acc: 0.7030\n",
            "Epoch: 015, Train Acc: 0.6783, Test Acc: 0.6980, Val Acc: 0.6770\n",
            "Epoch: 016, Train Acc: 0.7061, Test Acc: 0.7250, Val Acc: 0.7060\n",
            "Epoch: 017, Train Acc: 0.7097, Test Acc: 0.7300, Val Acc: 0.7020\n",
            "Epoch: 018, Train Acc: 0.7103, Test Acc: 0.7280, Val Acc: 0.7070\n",
            "Epoch: 019, Train Acc: 0.7110, Test Acc: 0.7330, Val Acc: 0.7020\n",
            "Epoch: 020, Train Acc: 0.7074, Test Acc: 0.7280, Val Acc: 0.6910\n",
            "Epoch: 021, Train Acc: 0.7053, Test Acc: 0.7210, Val Acc: 0.7050\n",
            "Epoch: 022, Train Acc: 0.7106, Test Acc: 0.7320, Val Acc: 0.7010\n",
            "Epoch: 023, Train Acc: 0.7079, Test Acc: 0.7240, Val Acc: 0.7040\n",
            "Epoch: 024, Train Acc: 0.7111, Test Acc: 0.7250, Val Acc: 0.7060\n",
            "Epoch: 025, Train Acc: 0.7106, Test Acc: 0.7240, Val Acc: 0.7100\n",
            "Epoch: 026, Train Acc: 0.7101, Test Acc: 0.7260, Val Acc: 0.7080\n",
            "Epoch: 027, Train Acc: 0.7026, Test Acc: 0.7180, Val Acc: 0.7060\n",
            "Epoch: 028, Train Acc: 0.7079, Test Acc: 0.7280, Val Acc: 0.7090\n",
            "Epoch: 029, Train Acc: 0.7050, Test Acc: 0.7210, Val Acc: 0.7060\n",
            "Epoch: 030, Train Acc: 0.7083, Test Acc: 0.7270, Val Acc: 0.6980\n",
            "Epoch: 031, Train Acc: 0.7080, Test Acc: 0.7300, Val Acc: 0.7000\n",
            "Epoch: 032, Train Acc: 0.7111, Test Acc: 0.7320, Val Acc: 0.6950\n",
            "Epoch: 033, Train Acc: 0.7091, Test Acc: 0.7240, Val Acc: 0.7060\n",
            "Epoch: 034, Train Acc: 0.6981, Test Acc: 0.7100, Val Acc: 0.7010\n",
            "Epoch: 035, Train Acc: 0.7117, Test Acc: 0.7240, Val Acc: 0.7080\n",
            "Epoch: 036, Train Acc: 0.7009, Test Acc: 0.7130, Val Acc: 0.7020\n",
            "Epoch: 037, Train Acc: 0.7154, Test Acc: 0.7290, Val Acc: 0.7000\n",
            "Epoch: 038, Train Acc: 0.7107, Test Acc: 0.7320, Val Acc: 0.7000\n",
            "Epoch: 039, Train Acc: 0.7081, Test Acc: 0.7350, Val Acc: 0.7000\n",
            "Epoch: 040, Train Acc: 0.7116, Test Acc: 0.7200, Val Acc: 0.7030\n",
            "Epoch: 041, Train Acc: 0.7130, Test Acc: 0.7260, Val Acc: 0.7010\n",
            "Epoch: 042, Train Acc: 0.7137, Test Acc: 0.7350, Val Acc: 0.7070\n",
            "Epoch: 043, Train Acc: 0.7143, Test Acc: 0.7260, Val Acc: 0.7070\n",
            "Epoch: 044, Train Acc: 0.7073, Test Acc: 0.7270, Val Acc: 0.7080\n",
            "Epoch: 045, Train Acc: 0.7116, Test Acc: 0.7260, Val Acc: 0.7060\n",
            "Epoch: 046, Train Acc: 0.7121, Test Acc: 0.7290, Val Acc: 0.6980\n",
            "Epoch: 047, Train Acc: 0.7151, Test Acc: 0.7290, Val Acc: 0.7070\n",
            "Epoch: 048, Train Acc: 0.7140, Test Acc: 0.7280, Val Acc: 0.7050\n",
            "Epoch: 049, Train Acc: 0.7146, Test Acc: 0.7250, Val Acc: 0.6970\n",
            "Epoch: 050, Train Acc: 0.7130, Test Acc: 0.7350, Val Acc: 0.6990\n",
            "Epoch: 051, Train Acc: 0.7080, Test Acc: 0.7220, Val Acc: 0.7010\n",
            "Epoch: 052, Train Acc: 0.7144, Test Acc: 0.7300, Val Acc: 0.6970\n",
            "Epoch: 053, Train Acc: 0.7074, Test Acc: 0.7220, Val Acc: 0.7040\n",
            "Epoch: 054, Train Acc: 0.7055, Test Acc: 0.7270, Val Acc: 0.6940\n",
            "Epoch: 055, Train Acc: 0.7137, Test Acc: 0.7320, Val Acc: 0.6960\n",
            "Epoch: 056, Train Acc: 0.7125, Test Acc: 0.7260, Val Acc: 0.7080\n",
            "Epoch: 057, Train Acc: 0.7067, Test Acc: 0.7280, Val Acc: 0.6990\n",
            "Epoch: 058, Train Acc: 0.7150, Test Acc: 0.7310, Val Acc: 0.6980\n",
            "Epoch: 059, Train Acc: 0.7095, Test Acc: 0.7220, Val Acc: 0.7100\n"
          ]
        }
      ],
      "source": [
        "model = GCNClassifier(5,32).to(torch.device('cuda'))\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(60):\n",
        "    train()\n",
        "    train_acc = test(train_loader)\n",
        "    test_acc = test(test_loader)\n",
        "    val_acc = test(val_loader)\n",
        "    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}, Val Acc: {val_acc:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oKfNaWogUrg",
        "outputId": "4a2a48f8-7cd0-4cde-e932-351f4ad76861"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.71"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test(val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "OPF-GI8-6SX2"
      },
      "outputs": [],
      "source": [
        "torch.save(model, \"gcn_gnn_gfc.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWtsBtcwh1IM",
        "outputId": "cade0444-34bb-4305-fbdc-430c0c3c0a1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 000, Train Acc: 0.5008, Test Acc: 0.4960, Val Acc: 0.5040\n",
            "Epoch: 001, Train Acc: 0.5009, Test Acc: 0.5050, Val Acc: 0.4990\n",
            "Epoch: 002, Train Acc: 0.5666, Test Acc: 0.5710, Val Acc: 0.5700\n",
            "Epoch: 003, Train Acc: 0.6757, Test Acc: 0.6790, Val Acc: 0.6610\n",
            "Epoch: 004, Train Acc: 0.6941, Test Acc: 0.7320, Val Acc: 0.7030\n",
            "Epoch: 005, Train Acc: 0.6865, Test Acc: 0.7160, Val Acc: 0.6810\n",
            "Epoch: 006, Train Acc: 0.6980, Test Acc: 0.7290, Val Acc: 0.7050\n",
            "Epoch: 007, Train Acc: 0.6965, Test Acc: 0.7270, Val Acc: 0.7050\n",
            "Epoch: 008, Train Acc: 0.7029, Test Acc: 0.7290, Val Acc: 0.7040\n",
            "Epoch: 009, Train Acc: 0.7044, Test Acc: 0.7300, Val Acc: 0.7060\n",
            "Epoch: 010, Train Acc: 0.7073, Test Acc: 0.7360, Val Acc: 0.7050\n",
            "Epoch: 011, Train Acc: 0.7057, Test Acc: 0.7320, Val Acc: 0.7070\n",
            "Epoch: 012, Train Acc: 0.7100, Test Acc: 0.7350, Val Acc: 0.7040\n",
            "Epoch: 013, Train Acc: 0.7080, Test Acc: 0.7370, Val Acc: 0.7010\n",
            "Epoch: 014, Train Acc: 0.7079, Test Acc: 0.7280, Val Acc: 0.7000\n",
            "Epoch: 015, Train Acc: 0.7093, Test Acc: 0.7320, Val Acc: 0.7080\n",
            "Epoch: 016, Train Acc: 0.7046, Test Acc: 0.7270, Val Acc: 0.6990\n",
            "Epoch: 017, Train Acc: 0.7111, Test Acc: 0.7380, Val Acc: 0.7050\n",
            "Epoch: 018, Train Acc: 0.7106, Test Acc: 0.7340, Val Acc: 0.7020\n",
            "Epoch: 019, Train Acc: 0.7151, Test Acc: 0.7330, Val Acc: 0.7060\n",
            "Epoch: 020, Train Acc: 0.7053, Test Acc: 0.7280, Val Acc: 0.7000\n",
            "Epoch: 021, Train Acc: 0.7129, Test Acc: 0.7180, Val Acc: 0.7100\n",
            "Epoch: 022, Train Acc: 0.7107, Test Acc: 0.7210, Val Acc: 0.7050\n",
            "Epoch: 023, Train Acc: 0.7173, Test Acc: 0.7320, Val Acc: 0.7080\n",
            "Epoch: 024, Train Acc: 0.7097, Test Acc: 0.7240, Val Acc: 0.7090\n",
            "Epoch: 025, Train Acc: 0.7155, Test Acc: 0.7310, Val Acc: 0.7160\n",
            "Epoch: 026, Train Acc: 0.7125, Test Acc: 0.7210, Val Acc: 0.7090\n",
            "Epoch: 027, Train Acc: 0.7173, Test Acc: 0.7330, Val Acc: 0.7060\n",
            "Epoch: 028, Train Acc: 0.7129, Test Acc: 0.7300, Val Acc: 0.7130\n",
            "Epoch: 029, Train Acc: 0.7159, Test Acc: 0.7280, Val Acc: 0.7170\n",
            "Epoch: 030, Train Acc: 0.7119, Test Acc: 0.7320, Val Acc: 0.7030\n",
            "Epoch: 031, Train Acc: 0.7184, Test Acc: 0.7340, Val Acc: 0.7130\n",
            "Epoch: 032, Train Acc: 0.7167, Test Acc: 0.7340, Val Acc: 0.7110\n",
            "Epoch: 033, Train Acc: 0.7104, Test Acc: 0.7200, Val Acc: 0.7070\n",
            "Epoch: 034, Train Acc: 0.7170, Test Acc: 0.7350, Val Acc: 0.7140\n",
            "Epoch: 035, Train Acc: 0.7149, Test Acc: 0.7350, Val Acc: 0.7050\n",
            "Epoch: 036, Train Acc: 0.7037, Test Acc: 0.7230, Val Acc: 0.7060\n",
            "Epoch: 037, Train Acc: 0.7150, Test Acc: 0.7340, Val Acc: 0.7060\n",
            "Epoch: 038, Train Acc: 0.7059, Test Acc: 0.7150, Val Acc: 0.7060\n",
            "Epoch: 039, Train Acc: 0.7154, Test Acc: 0.7250, Val Acc: 0.7170\n",
            "Epoch: 040, Train Acc: 0.7121, Test Acc: 0.7260, Val Acc: 0.7120\n",
            "Epoch: 041, Train Acc: 0.7073, Test Acc: 0.7300, Val Acc: 0.7090\n",
            "Epoch: 042, Train Acc: 0.7104, Test Acc: 0.7270, Val Acc: 0.7080\n",
            "Epoch: 043, Train Acc: 0.7147, Test Acc: 0.7230, Val Acc: 0.7110\n",
            "Epoch: 044, Train Acc: 0.7061, Test Acc: 0.7200, Val Acc: 0.7010\n",
            "Epoch: 045, Train Acc: 0.7159, Test Acc: 0.7340, Val Acc: 0.7170\n",
            "Epoch: 046, Train Acc: 0.7201, Test Acc: 0.7340, Val Acc: 0.7040\n",
            "Epoch: 047, Train Acc: 0.7089, Test Acc: 0.7200, Val Acc: 0.7040\n",
            "Epoch: 048, Train Acc: 0.7005, Test Acc: 0.7230, Val Acc: 0.6960\n",
            "Epoch: 049, Train Acc: 0.7096, Test Acc: 0.7230, Val Acc: 0.7050\n",
            "Epoch: 050, Train Acc: 0.7121, Test Acc: 0.7160, Val Acc: 0.7150\n",
            "Epoch: 051, Train Acc: 0.7165, Test Acc: 0.7270, Val Acc: 0.7110\n",
            "Epoch: 052, Train Acc: 0.7019, Test Acc: 0.7080, Val Acc: 0.7010\n",
            "Epoch: 053, Train Acc: 0.7199, Test Acc: 0.7380, Val Acc: 0.7110\n",
            "Epoch: 054, Train Acc: 0.7160, Test Acc: 0.7340, Val Acc: 0.7080\n",
            "Epoch: 055, Train Acc: 0.7096, Test Acc: 0.7260, Val Acc: 0.7100\n",
            "Epoch: 056, Train Acc: 0.7180, Test Acc: 0.7340, Val Acc: 0.7150\n",
            "Epoch: 057, Train Acc: 0.7194, Test Acc: 0.7350, Val Acc: 0.7090\n",
            "Epoch: 058, Train Acc: 0.7010, Test Acc: 0.7020, Val Acc: 0.7080\n",
            "Epoch: 059, Train Acc: 0.7205, Test Acc: 0.7340, Val Acc: 0.7180\n"
          ]
        }
      ],
      "source": [
        "model = GATClassifier(5,32).to(torch.device('cuda'))\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(60):\n",
        "    train()\n",
        "    train_acc = test(train_loader)\n",
        "    test_acc = test(test_loader)\n",
        "    val_acc = test(val_loader)\n",
        "    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}, Val Acc: {val_acc:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQBGwAkiisFr",
        "outputId": "9967697c-a56b-4a0c-8c3f-a6c7a85a6822"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.718"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test(val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "OFJK9Nzvs70i"
      },
      "outputs": [],
      "source": [
        "torch.save(model, \"gat_gnn_gfc.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "QQCzLUp2oSrl"
      },
      "outputs": [],
      "source": [
        "del train_loader\n",
        "del test_loader\n",
        "del val_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Inference**\n",
        "\n",
        "1. The accuracy of each model, except SAGEConv(due to a sampling of neighbours giving Graph SAGE its efficiency), increased with higher k values. \n",
        "2. The maximum recorded accuracy was 71.8% using the GAT-Classifier after 60 epochs.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
